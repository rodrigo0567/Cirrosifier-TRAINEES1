{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue\"><center> **CLASSIFICAÇÃO DOS EPISÓDIOS DE MORTE DECORRENTE DA CIRROSE**</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, vamos elaborar um processo de classificação com base no dataset [Liver Cirrhosis Stage Classification](https://www.kaggle.com/datasets/aadarshvelu/liver-cirrhosis-stage-classification), com o objetivo de classificar a coluna **\"Situação\"**. Ou seja, criaremos modelos com Regressão Logística, Árvore de Decisão e Rede Neural, e por último, LGBM (Light Gradient Boosting Machine), para identificar os casos de Sobrevivência, Morte e Transplante dos pacientes de cirrose, vistos na EDA.\n",
    "\n",
    "Para isso, nós realizamos 3 classificações diferentes:\n",
    "\n",
    "**1. Morte, Sobrevivência e Transplante**\n",
    "- Essa primeira classificação contém as 3 classes, não modificamos nada no dataset. O ponto dela é ser capaz de distinguir os 3 casos individualmente.\n",
    "\n",
    "**2. Mesclando Sobrevivência e Transplante**\n",
    "- Aqui, nós juntamos as classes *Sobrevivência* e *Transplante* em uma só, com a finalidade de identificar binariamente a situação dos pacientes estudados: ou morto ou vivo.\n",
    "\n",
    "**3. Ignorando Evento Transplante**\n",
    "- Por último, fizemos uma classificação deixando de lado a classe *Transplante*, levando em consideração apenas os atributos dos pacientes que sobreviveram que não necessitaram da operação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando as Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump, load\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') # Remoção apenas para fins estéticos do Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Antes de tudo vamos importar o csv \"liver_cirrhosis_v3\". Essa versão foi separada previamente durante a etapa de limpeza de dados, removendo algumas variáveis da tabela e deixando apenas as mais relevantes para a classificação de casos de morte. Esses atributos são:\n",
    "\n",
    "    - `Situação (Sobreviveu, Transplante ou Morte)`\n",
    "    - `Idade (dias)`\n",
    "    - `Sexo (M ou F)`\n",
    "    - `Bilirrubina (mg/dl)`\n",
    "    - `Albumina (gm/dl)`\n",
    "    - `Fosfatase Alcalina (U/L)`\n",
    "    - `Aspartato Aminotransferase (U/L)`\n",
    "    - `Plaquetas (ml/1000)`\n",
    "    - `Tempo de Protrombina (s)`\n",
    "    - `Estágio (1, 2 ou 3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para fins de legibilidade e funcionamento dos códigos do notebook, vamos modificar a coluna Sexo com um label encoder do sklearn, para que ao invés de ser uma coluna de strings (M ou F), ela seja uma coluna binária (0 ou 1). Nesse caso, as linhas com valor 0 serão do sexo feminino e com valor 1 serão do sexo masculino (essa é a ordem que o label encoder coloca por padrão). Por isso, ela também será renomeada para Sexo Masculino, já que: 0 (false) = Feminino e 1 (true) = Masculino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/dados_processados/liver_cirrhosis_v3.csv\")\n",
    "\n",
    "# Instanciar o Label Encoder para converter as colunas String\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Sexo'] = label_encoder.fit_transform(df['Sexo'])\n",
    "\n",
    "df.rename(\n",
    "    columns={'Sexo':'Sexo Masculino'}, # Mudando 'Sexo' para 'Sexo Masculino', \n",
    "    inplace=True # Realiza a mudança no prórprio df\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Classificação 1: Morte, Sobrevivência e Transplante\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação e Ajuste dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com o dataset extraído, a próxima etapa será dividir as variáveis *X* e *y*. Como queremos classificar a coluna *Situação* e prever os casos de *sobrevivência*, *morte* e *transplante*\", vamos definir essa coluna como sendo a *y*. O resto das colunas usaremos como valores de entrada sendo a variável *X*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "# Obtendo as variáveis x e y para treinar o modelo \n",
    "X1  = df1.drop(columns=['Situação']).values\n",
    "y1 = df1['Situação'].values\n",
    "\n",
    "print(X1)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Separação e Normalização dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos dividir cada uma de nossas variáveis em duas partes, uma fração para treino e outra para testes. Nesse caso, decidimos dividir 80% dos valores para treino e o restante, que seria 20%, para os testes mais para frente.\n",
    "\n",
    "* Seguindo, agora é hora de normalizar os dados que separamos. Para isso, é utilizado o objeto **StandardScaler** e seus métodos *fit_transform()* e *fit()*. Depois de aplicada a normalização, nós salvamos o scaler na pasta *scalers* com o nome *death_scaler.joblib* para possíveis usos futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo 80% da matriz para treinar o modelo e 20% para os testes\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2)\n",
    "print(\"Tamanho separado para treinos: \" + str(len(X_train1)))\n",
    "print(\"Tamanho separado para testes: \" + str(len(X_test1)) + \"\\n\")\n",
    "\n",
    "# Normalizando os dados extraídos do dataset\n",
    "scaler1 = StandardScaler()\n",
    "X_train1_scaled = scaler1.fit_transform(X_train1)\n",
    "X_test1_scaled = scaler1.transform(X_test1)\n",
    "\n",
    "# Salvando o scaler para uso futuro\n",
    "print(\"O modelo do scaler foi salvo em:\")\n",
    "dump(scaler1, 'scalers/scalers_morte/death_scaler1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regressão Logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nosso primeiro modelo de classificação será utilizando Regressão Logística. Vamos utilizar o objeto **LogisticRegression** e dar um *fit()* para poder treinar nosso modelo, e depois salvar a predição numa variável separada. Os resultados da regressão são exibidos através de uma tabela de resultados, com a precisão de cada classe e a acurácia geral, e também uma matriz de confusão com as três classes.\n",
    "\n",
    "* Por fim, o modelo de Regressão Logística é salvo na pasta *models* no arquivo nomeado *death_logreg1.joblib* para que seja mais fácil acessá-lo caso seja necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo\n",
    "logreg1 = LogisticRegression(max_iter=4000, n_jobs=-1, C=0.1, penalty='l2')\n",
    "logreg1.fit(X_train1_scaled, y_train1)\n",
    "\n",
    "# Predict com dados de treino\n",
    "y_pred1T = logreg1.predict(X_train1_scaled)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Regressão Logística - Treino:\")\n",
    "print(classification_report(y_train1, y_pred1T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict do teste\n",
    "y_pred1 = logreg1.predict(X_test1_scaled)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Regressão Logística - Teste:\")\n",
    "print(classification_report(y_test1, y_pred1, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Na regressão logística, estamos obtendo uma acurácia na faixa dos 70%, o que não é tão ruim, mas poderia ser bem melhor. Isso se dá, em partes devido à natureza sintética dos dados encontrados no dataset. Outro fator que também torna esse modelo inadequado é a exclusão total da classe **Transplante**: perceba que ela não está sendo classificada. Isso se deve ao desbalanceamento do dataset: tem muitos poucos casos com essa classe comparada às outras, algo que torna o desempenho do algoritmo de regressão logística impreciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "coefficients1 = logreg1.coef_\n",
    "importance1 = pd.DataFrame(coefficients1.T, columns = logreg1.classes_, index=df1.drop('Situação', axis=1).columns)\n",
    "print(\"\\nImportância dos coeficientes:\")\n",
    "print(importance1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos avaliar os 3 atributos mais importantes para cada classe.\n",
    "\n",
    "    * **Morte**\n",
    "        - Idade: O aumento na idade dos pacientes tende a torná-los mais vulneráveis, portanto é impactante pra classificar os casos de morte.\n",
    "        - Bilirrubina (mg/dl): Fortemente associada ao mal funcionamento do fígado, logo também é bastante impactante.\n",
    "        - Fosfatase Alcalina (U/L): Importância diretamente proporcional, pois taxas altas desse químico sugerem obstruções no fluxo do fígado.\n",
    "\n",
    "    * **Sobreviveu**\n",
    "        - Bilirrubina (mg/dl): Oposta a importância que teve na classe Morte, já que as taxas menores significam que o fígado está mais saudável.\n",
    "        - Aspartato Aminotransferase (U/L): Valores altos indicam dano nas células do fígado, portanto valores menores importam para os casos de sobrevivência.\n",
    "        - Estágio: Quanto menor o estágio, mais fácil é do paciente sobreviver a doença. Portanto é de se esperar que valores baixos tenham mais importância aqui.\n",
    "        \n",
    "    * **Transplante**\n",
    "        - Idade: Perceba que tem importância pro lado negativo, sugerindo que as pessoas tendem a optar pelo transplante em idades mais jovens.\n",
    "        - Bilirrubina (mg/dl): Influência positiva, assim como na classe Morte. Pode sugerir que pessoas com altas taxas procuram o transplante como solução.\n",
    "        - Fosfatase Alcalina (U/L): Diferente das outras duas classes, aqui tem importância pro lado negativo, refletindo a possível melhora no funcionamento do fígado após o transplante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criar matrizes de confusão nos ajuda a visualizar melhor as distribuições das classificações dos nossos modelos, então vamos fazer isso para cada um dos algoritmos no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrix1 = confusion_matrix(y_test1, y_pred1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixPlot1 = ConfusionMatrixDisplay(confusion_matrix=matrix1, display_labels=logreg1.classes_)\n",
    "matrixPlot1.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Regressão Logística - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceba que na 1° linha, a de Morte, a matriz apresenta valores dispersos entre a 1° e 2° coluna. Isso se dá a baixa taxa de recall que o modelo desenvolveu, refletindo que nosso modelo está prevendo casos que deveriam ser de Morte como Sobreviveu, erroneamente.\n",
    "\n",
    "* Em Transplante é possivel verificar que o modelo não foi capaz de classificar corretamente. Isso pode ter ocorrido pela observação que citamos anteriormente, não existem dados suficientes de transplante para que seja possivel a classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo de regressão para uso futuro\n",
    "print(\"O modelo de Regressão Logística foi salvo em:\")\n",
    "dump(logreg1, 'models/modelos_morte/death_logreg1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agora vamos realizar outra alternativa de classificação. Dessa vez, vamos utilizar o algoritmo de Árvore de Decisão, que pode ser útil para nos ajudar a visualizar melhor o que está acontecendo no processo de classificação, e talvez até entregue resultados melhores na acurácia e precisão.\n",
    "\n",
    "* Perceba que podemos utilizar as mesmas variáveis X e y, já que não foram modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar a Árvore de Decisão\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_leaf=5)\n",
    "\n",
    "clf1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict com dados de treino\n",
    "tree_pred1T = clf1.predict(X_train1)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão - Treino:\")\n",
    "print(classification_report(y_train1, tree_pred1T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão\n",
    "tree_pred1 = clf1.predict(X_test1)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão - Teste:\")\n",
    "print(classification_report(y_test1, tree_pred1, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceba que a acurácia aumentou consideravelmente, de aproximadamente 70% para aproximadamente 80%. Além disso, a classe **Transplante**, que antes estava sendo omitida da classificação, agora está sendo classificada corretamente. Maravilha! Além disso, aqui não está tendo overfitting já que a acurácia se mantém similar entre a classificação com dados de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances1 = clf1.feature_importances_\n",
    "feature_importances1 = pd.DataFrame(\n",
    "    importances1,\n",
    "    columns = ['Importance'],\n",
    "    index=df1.drop('Situação', axis=1).columns\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Forte Importância:\n",
    "    - Bilirrubina(mg/dl): 0.627105\n",
    "* Importância Moderada:\n",
    "    - Aspartato_Aminotransferase(U/L): 0.111300\n",
    "    - Fosfatase_Alcalina (U/L): 0.104742\n",
    "    - Albumina(gm/dl): 0.085476\n",
    "* Importância Fraca:\n",
    "    - Tempo_de_Protrombina(s): 0.040876\n",
    "    - Estágio: 0.030501\n",
    "    - Idade: 0.000000\n",
    "    - Plaquetas(ml/1000): 0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agora vamos plotar a nossa árvore de decisão, para que possamos visualizar as etapas que o modelo tomou para alcançar tais resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottar a Árvore de Decisão\n",
    "fig1 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf1,\n",
    "                      feature_names=df1.drop(columns=['Situação']).columns,\n",
    "                      class_names=clf1.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree1 = confusion_matrix(y_test1, tree_pred1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot1 = ConfusionMatrixDisplay(confusion_matrix=matrixTree1, display_labels=clf1.classes_)\n",
    "matrixTreePlot1.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matriz de confusão da árvore, diferentemente da matriz de regressão, agora possui valores na coluna *Transplantes*, o que quer dizer que nosso modelo está finalmente sendo capaz de prever e distinguir casos onde os pacientes realizaram um transplante. Ademais, a matriz está mais definida, com valores concentrados na diagonal principal, o que quer dizer que a nossa acurácia está bem alta, prevendo corretamente a grande maioria dos casos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando os resultados da Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1[645]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_rules(clf, x_sample):\n",
    "    #Id das features analisadas em cada nó da árvore de decisão\n",
    "    feature = clf.tree_.feature\n",
    "\n",
    "    #Limiar de decisão de cada nó da árvore\n",
    "    threshold = clf.tree_.threshold\n",
    "\n",
    "    #Acessa o caminho de nós da árvore até a folha de predicao da amostra\n",
    "    node_indices = clf.decision_path([x_sample]).indices \n",
    "   \n",
    "    #Último nó do caminho é a folha de predição\n",
    "    leaf_id = node_indices[-1]\n",
    "   \n",
    "    print('\\nFeatures usadas para predizer a amostra')\n",
    "\n",
    "    for f, v in zip(df.drop(columns=['Situação']).columns, x_sample):\n",
    "        print('%s = %s'%(f,v))\n",
    "    print('\\n')      \n",
    "\n",
    "    for node_id in node_indices:\n",
    "        if leaf_id == node_id:\n",
    "            break\n",
    "\n",
    "\n",
    "        if (x_sample[feature[node_id]] <= threshold[node_id]):\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "\n",
    "        print(\"id do nó de decisão %s : (atributo %s com valor = %s %s %s)\"\n",
    "              % (node_id,\n",
    "                 df.drop(columns=['Situação']).columns[feature[node_id]],\n",
    "                 x_sample[feature[node_id]],\n",
    "                 threshold_sign,\n",
    "                 threshold[node_id]))\n",
    "        \n",
    "    pred = clf.predict([x_sample])\n",
    "\n",
    "    print(\"\\tClasse => %s\" %pred)\n",
    "\n",
    "\n",
    "extract_rules(clf1, X_test1[645])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reestruturação da Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A nossa árvore de decisão está entregando bons resultados, mas está bem ilegível. Para corrigir isso, vamos modificar alguns parâmetros para que a análise fique mais sucinta (e de fato possível).\n",
    "\n",
    "* Na primeira árvore, nós utilizamos valores selecionados a dedo por um processo de tentativa e erro para tentar torná-la aceitável. Como solução mais prática, podemos realizar uma *Grid Search* para automaticamente encontrar o melhor valor para os parâmetros da árvore de decisão. No código, ao lado de cada parâmetro há um comentário explicando brevemente a função de cada parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "path1 = clf1.cost_complexity_pruning_path(X_train1, y_train1)\n",
    "\n",
    "param_grid1 = {\n",
    "    'max_depth': range(2, 10), # Profundidade da árvore, limita o quanto a árvore pode crescer\n",
    "    'min_samples_split': range(2, 10), # A quantidade mínima de samples para separar cada caminho da árvore\n",
    "    'min_samples_leaf': range(1, 5), # O mínimo de samples que deve estar em cada folha da árvore\n",
    "    'criterion': ['gini', 'entropy'], # Critérios de partição da árvore\n",
    "    'max_features': range(4, X1.shape[1] + 1), # Limita o número de características avaliadas\n",
    "    'ccp_alpha': (0.0, 0.1, 0.5, 0.05, 0.005) # Penalizador utilizado para regular a árvore\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=clf1, param_grid=param_grid1, cv = 7, verbose=2, n_jobs=-1)\n",
    "CV_clf.fit(X_train1, y_train1)\n",
    "\n",
    "best_max_depth1 = CV_clf.best_estimator_.max_depth\n",
    "best_min_split1 = CV_clf.best_estimator_.min_samples_split\n",
    "best_min_leaf1 = CV_clf.best_estimator_.min_samples_leaf\n",
    "best_criterion1 = CV_clf.best_estimator_.criterion\n",
    "best_max_features1 = CV_clf.best_estimator_.max_features\n",
    "best_ccp_alpha1 = CV_clf.best_estimator_.ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com os valores em mãos, agora vamos criar outra árvore de decisão com os parâmetros modificados, com o objetivo de torná-la mais agradável esteticamente sem que haja uma diminuição muito grande da acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar um novo objeto para a Árvore de Decisão Reestruturada\n",
    "clf_ccp1 = DecisionTreeClassifier(criterion=best_criterion1,\n",
    "                                   max_depth=6, # O resultado do GridSearch acaba tornando a árvore muito ilegível, então vamos manter 6 aqui\n",
    "                                   min_samples_leaf=best_min_leaf1, \n",
    "                                   min_samples_split=best_min_split1, \n",
    "                                   ccp_alpha=best_ccp_alpha1,\n",
    "                                   max_features=best_max_features1)\n",
    "\n",
    "clf_ccp1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict da Árvore de Decisão Reestruturada - Treino\n",
    "tree_pred1T = clf_ccp1.predict(X_train1)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Dados de Treino:\")\n",
    "print(classification_report(y_train1, tree_pred1T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão Reestruturada - Teste\n",
    "tree_pred1 = clf_ccp1.predict(X_test1)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Teste:\")\n",
    "print(classification_report(y_test1, tree_pred1, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com as limitações que colocamos na árvore, a acurácia agora parece se estabilizar na faixa dos 80%, o que é ótimo pois não houve uma diminuição tão considerável da árvore anterior e ainda assim conseguimos tornar a árvore bem mais interpretável. O modelo se mantém sem overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances1 = clf_ccp1.feature_importances_\n",
    "feature_importances1 = pd.DataFrame(\n",
    "    importances1,\n",
    "    columns = ['Importance'],\n",
    "    index=df1.drop('Situação', axis=1).columns\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão Reestruturada\n",
    "fig_1 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf_ccp1,\n",
    "                      feature_names=df1.drop(columns=['Situação']).columns,\n",
    "                      class_names=clf_ccp1.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree1 = confusion_matrix(y_test1, tree_pred1)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot1 = ConfusionMatrixDisplay(confusion_matrix=matrixTree1, display_labels=clf_ccp1.classes_)\n",
    "matrixTreePlot1.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão Reestruturada - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nessa matriz de confusão, podemos notar que, infelizmente, o recall da classe *Transplante* diminuiu, mas isso é consequência do processo que fizemos para tornar a árvore mais legível. Mesmo assim, o elemento 3x3 ainda possui a maior quantia da linha 3, o que significa que, em maioria, o modelo está prevendo corretamente os casos de transplante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, vamos salvar arquivos dos nossos modelos de árvore de decisão para que possamos usá-las em outra situação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de Árvore de Decisão Corrigida foi salvo em:\")\n",
    "dump(clf_ccp1, 'models/modelos_morte/death_tree_fixed1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rede Neural**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nessa seção, vamos mudar o foco para utilizar um modelo de Rede Neural nas previsões. Como a rede neural exige que as classes sejam números, e não strings, é necessário fazer um **label encoding** com a biblioteca do sklearn para deixar a coluna *Situação* em números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1N = df.copy()\n",
    "df1N['Situação'] = label_encoder.fit_transform(df1N['Situação'])\n",
    "\n",
    "X1N  = df1N.drop(columns=['Situação']).values\n",
    "y1N = df1N['Situação'].values\n",
    "\n",
    "X_train1N, X_test1N, y_train1N, y_test1N = train_test_split(X1N, y1N, test_size=0.2)\n",
    "X_train1N = scaler1.fit_transform(X_train1N)\n",
    "X_test1N = scaler1.transform(X_test1N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aqui estamos inicializando uma rede neural com:\n",
    "\n",
    "    * camada de entrada com 32 neurônios e função de ativação *relu*;\n",
    "\n",
    "    * duas camadas com 64 neurônios;\n",
    "\n",
    "    * uma camada com 32 neurônios;\n",
    "\n",
    "    * camada de saída com 2 neurônios (para as duas classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train1N.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A partir dessa célula, temos o treinamento do modelo de fato. Vamos rodar 200 épocas de 64 amostras cada, para conseguir fazer um treino relativamente rápido e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = neural1.fit(X_train1N, y_train1N, epochs=200, batch_size=64, validation_data=(X_test1N, y_test1N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perceba que a acurácia parece parar na faixa dos 85%. Poderíamos continuar, mas não iria mudar tanto. Abaixo, gráficos que facilitam visualizar o crescimento da acurácia na nossa rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy/loss\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_acc, label='Acurácia do Treino')\n",
    "plt.plot(val_acc, label='Acurácia dos Testes')\n",
    "plt.title('Curva das Acurácias (Melhor Modelo)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss (error)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Perda do Treino')\n",
    "plt.plot(val_loss, label='Perda dos Testes')\n",
    "plt.title('Curvas das Perdas (Melhor Modelo)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depois de tudo isso, printar os reports da classificação para analisar os resultados finais do nosso modelo (e novamente checar se está acontecendo overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Report - Rede Neural - Treino:\")\n",
    "print(classification_report(y_train1N, np.argmax(neural1.predict(X_train1N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Report - Rede Neural - Teste:\")\n",
    "print(classification_report(y_test1N, np.argmax(neural1.predict(X_test1N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enfim, vamos salvar o modelo de Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de Rede Neural foi salvo em:\")\n",
    "dump(neural1, 'models/modelos_morte/death_neural1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Light Gradient Boosting Machine (LGBM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como uma análise final, vamos finalmente realizar a classificação utilizando dessa vez o **Light Gradient Boosting Machine** (ou LGBM). Esse modelo, diferente dos outros, faz um processo de ensemble de tipo boosting, que vai combinar vários modelos do mesmo algoritmo de forma sequencial para tornar o modelo muito mais eficaz e prático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando as mesmas variáveis da Rede Neural, pois já estão reguladas pelo label encoder\n",
    "train_data1 = lgb.Dataset(X_train1N, label=y_train1N)\n",
    "valid_data1 = lgb.Dataset(X_test1N, label= y_test1N)\n",
    "\n",
    "# Define os parâmetros do modelo\n",
    "parameters1 = {\n",
    "    'objective': 'multiclass',  # Define o objetivo como classificação multiclasse\n",
    "    'boosting_type': 'gbdt',  # Usa Gradient Boosting Decision Tree\n",
    "    'metric': 'multi_logloss',  # Métrica de avaliação: log-loss para múltiplas classes\n",
    "    'num_class': len(np.unique(y_test1N)),  # Número de classes únicas em 'Situação'\n",
    "    'num_leaves': 31,  # Número máximo de folhas em cada árvore\n",
    "    'learning_rate': 0.05,  # Taxa de aprendizado do modelo\n",
    "    'feature_fraction': 0.9  # Fração de features usadas em cada iteração de construção da árvore\n",
    "}\n",
    "\n",
    "# Treina o modelo\n",
    "model_lgbm1 = lgb.train(parameters1, train_data1, valid_sets=[train_data1, valid_data1], num_boost_round=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsões\n",
    "y_train_pred_1 = model_lgbm1.predict(X_train1N)\n",
    "y_valid_pred_1 = model_lgbm1.predict(X_test1N)\n",
    "\n",
    "# Converte as previsões para rótulos de classe\n",
    "y_train_pred_1_labels = np.argmax(y_train_pred_1, axis=1)\n",
    "y_valid_pred_1_labels = np.argmax(y_valid_pred_1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depois de treinar o modelo, vamos checar as tabelas para tomar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de resultado com os dados de treino\n",
    "print(\"Report - LGBM - Treino:\")\n",
    "print(classification_report(y_train1N, y_train_pred_1_labels, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados com os dados de\n",
    "print(\"Report - LGBM - Teste:\")\n",
    "print(classification_report(y_test1N, y_valid_pred_1_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Algo interessante que acontece aqui é que o modelo conseguiu alcançar uma porcentagem de **100% de acurácia** nos dados de treino! Isso normalmente poderia ser preocupante, mas perceba que a acurácia nos dados de teste se mantém na faixa dos 97%, o que é extremamente bom e similar a do treino, logo não há overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixLGBM1T = confusion_matrix(y_test1N, y_valid_pred_1_labels)\n",
    "print(matrixLGBM1T)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "matrixLGBMPlot1 = ConfusionMatrixDisplay(confusion_matrix=matrixLGBM1T, display_labels=np.unique(y_test1))\n",
    "matrixLGBMPlot1.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('LightGBM - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matriz de confusão deixa ainda mais evidente a eficácia do LGBM. O recall do modelo está ótimo, já que a maior concentração das previsões está de fato onde deveriam estar, linha batendo com coluna (1x1, 2x2, 3x3). As cores fortes na diagonal principal significam que a grande maioria das previsões está batendo com os dados reais.\n",
    "\n",
    "* Para finalizar nossa classificação, vamos salvar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "print(\"O modelo de LightGBM foi salvo em:\")\n",
    "dump(model_lgbm1, 'models/modelos_morte/death_lightgbm1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Classificação 2: Mesclando Sobrevivência e Transplante\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação e Ajuste dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Junção dos dados de *Sobreviveu* e *Transplante* em uma única classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# Considerando o valor de \"Transplante\" como \"Sobreviveu\"\n",
    "df2['Situação'] = df2['Situação'].replace('Transplante', 'Sobreviveu')\n",
    "\n",
    "print(df2['Situação'].value_counts())\n",
    "#df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A coluna **\"Situação\"** passa a ter apenas duas classes: *Sobreviveu* e *Morte*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Separação e Normalização dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividimos as colunas nas variáveis X2 e y2.\n",
    "\n",
    "* Separamos os dados de ambas as variáveis em 80% para treino e 20% para teste.\n",
    "\n",
    "* Normalizamos os dados de X2 utilizando o *StandardScaler* e salvamos o scaler na pasta **scalers** para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2.iloc[:, 1:].values\n",
    "y2 = df2.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_train2)\n",
    "X_train2_scaled = scaler2.transform(X_train2)\n",
    "X_test2_scaled = scaler2.transform(X_test2)\n",
    "\n",
    "print(\"Tamanho treinamento: \" + str(len(X_train2)))\n",
    "print(\"Tamanho teste: \" + str(len(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo do scaler foi salvo em:\")\n",
    "dump(scaler2, 'scalers/scalers_morte/death_scaler2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regressão Logistica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nosso primeiro modelo de classificação será utilizando Regressão Logística. Vamos utilizar o objeto LogisticRegression e dar um fit() para treinar nosso modelo, e depois salvar a predição eu uma variável separada. Os resultados da regressão são exibidos através de uma tabela de resultados, com a precisão de cada classe, a acurácia geral e também uma matriz de confusão com as duas classes.\n",
    "\n",
    "* Por fim, o modelo de Regressão Logística é salvo na pasta *models*, no arquivo nomeado *death_logreg2.joblib*, para que seja mais fácil de acessá-lo caso seja necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogisticRegression(max_iter=4000, n_jobs=-1, C=0.1, penalty='l2')\n",
    "logreg2.fit(X_train2_scaled, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict do treino\n",
    "y_pred2T = logreg2.predict(X_train2_scaled)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Regressão Logística - Treino:\")\n",
    "print(classification_report(y_train2, y_pred2T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict do teste\n",
    "y_pred2 = logreg2.predict(X_test2_scaled)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Regressão Logística - Teste:\")\n",
    "print(classification_report(y_test2, y_pred2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pelos resultados das acurácias do treino e do teste serem similares, podemos concluir que o modelo não está sofrendo de overfitting. Apesar disso, a acurácia do modelo não é tão alta, ficando com valores por volta de 75%. Logo, podemos continuar explorando outros modelos de classificação para tentar melhorar esse valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "feature_names2 = df2.columns[1:]\n",
    "coefficients2 = logreg2.coef_\n",
    "coef_df2 = pd.DataFrame(coefficients2, columns=feature_names2)\n",
    "for i, class_name in enumerate(logreg2.classes_):\n",
    "    sorted_coef2 = coef_df2.iloc[i].sort_values(ascending=False)\n",
    "    print(f\"Importância das Features em relação a {class_name}:\\n\")\n",
    "    print(sorted_coef2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Percebemos que a *Bilirrubina*, o *Estágio* e o *Tempo de Protrombina* são as variáveis mais influentes para a classificação. Isso ocorre pois a bilirrubina é um indicador que está relacionado à falha da função hepática ou obstrução biliar, o estágio da cirrose é um indicador da gravidade da doença e o tempo de protrombina é um indicador da capacidade de coagulação do sangue. Portanto, quanto maior a magnitude dessas variáveis, maior a probabilidade de morte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrix2 = confusion_matrix(y_test2, y_pred2)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixPlot2 = ConfusionMatrixDisplay(confusion_matrix=matrix2, display_labels=logreg2.classes_)\n",
    "matrixPlot2.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Regressão Logística - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matriz nos mostra que, apesar de acertar a maioria dos casos de sobrevivência, o modelo tem dificuldade em classificar os casos de morte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo de regressão para uso futuro\n",
    "print(\"O modelo de Regressão Logística foi salvo em:\")\n",
    "dump(logreg2, 'models/modelos_morte/death_logreg2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agora vamos tentar outra alternativa de classificação. Dessa vez, vamos tentar utilizar o algoritmo de Árvore de Decisão, que pode ser útil para nos ajudar a visualizar melhor o que está acontecendo no processo de classificação e, possivelmente entregue resultados melhores na acurácia e precisão.\n",
    "\n",
    "* Perceba que podemos utilizar as mesmas variáveis X e y, já que não foram modificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree2, X_test_tree2, y_train_tree2, y_test_tree2 = train_test_split(X2, y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar a Árvore de Decisão\n",
    "clf2 = DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_leaf=5)\n",
    "\n",
    "clf2.fit(X_train_tree2, y_train_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão - Treino\n",
    "tree_pred2T = clf2.predict(X_train_tree2)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão - Treino:\")\n",
    "print(classification_report(y_train_tree2, tree_pred2T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão - Teste\n",
    "tree_pred2 = clf2.predict(X_test_tree2)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão - Teste:\")\n",
    "print(classification_report(y_test_tree2, tree_pred2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pelos resultados das acurácias do treino e do teste serem similares, podemos concluir que o modelo não está sofrendo de overfitting. Além disso, percebemos que a acurácia do modelo melhorou, ficando na faixa dos 85%. Porém, apesar de apresentar melhora significativa em relação ao modelo de Regressão Logística, a acurácia pode ser melhorada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances2 = clf2.feature_importances_\n",
    "feature_importances2 = pd.DataFrame(\n",
    "    importances2,\n",
    "    columns = ['Importance'],\n",
    "    index=df2.drop('Situação', axis=1).columns\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neste modelo, notamos que a *Bilirrubina* é a variável mais influente para a classificação. Além disso, podemos perceber que as demais variáveis possuem um impacto menor na classificação quando comparados ao modelo de Regressão Logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottar a Árvore de Decisão\n",
    "fig2 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf2,\n",
    "                      feature_names=df2.drop(columns=['Situação']).columns,\n",
    "                      class_names=clf2.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree2 = confusion_matrix(y_test_tree2, tree_pred2)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot2 = ConfusionMatrixDisplay(confusion_matrix=matrixTree2, display_labels=clf2.classes_)\n",
    "matrixTreePlot2.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matriz de confusão da árvore, diferentemente da matriz de regressão, agora possui muito mais valores de morte corretamente classificados. Além disso, a matriz está bem mais definida, com valores concentrados na diagonal principal, o que quer dizer que a nossa acurácia está melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando os resultados da Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rules(clf2, X_test2[123])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reestruturação da Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A nossa Árvore de Decisão está entregando bons resultados, mas ainda pode melhorar. Para isso, vamos usar o GridSearchCV para encontrar os melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "path2 = clf2.cost_complexity_pruning_path(X_train_tree2, y_train_tree2)\n",
    "\n",
    "param_grid2 = {\n",
    "    'max_depth': range(2, 10),\n",
    "    'min_samples_split': range(2, 10),\n",
    "    'min_samples_leaf': range(1, 5),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': range(4, X2.shape[1] + 1),\n",
    "    'ccp_alpha': (0.0, 0.1, 0.5, 0.05, 0.005)\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=clf2, param_grid=param_grid2, cv = 7, verbose=2, n_jobs=-1)\n",
    "CV_clf.fit(X_train_tree2, y_train_tree2)\n",
    "\n",
    "best_max_depth2 = CV_clf.best_estimator_.max_depth\n",
    "best_min_split2 = CV_clf.best_estimator_.min_samples_split\n",
    "best_min_leaf2 = CV_clf.best_estimator_.min_samples_leaf\n",
    "best_criterion2 = CV_clf.best_estimator_.criterion\n",
    "best_max_features2 = CV_clf.best_estimator_.max_features\n",
    "best_ccp_alpha2 = CV_clf.best_estimator_.ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com os melhores valores, agora podemos criar outra árvore de decisão com tais parâmetros modificados, com o objetivo de melhorar a apresentação da Árvore sem afetar, de forma significativa a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar um novo objeto para a Árvore de Decisão Reestruturada\n",
    "clf_ccp2 = DecisionTreeClassifier(criterion=best_criterion2,\n",
    "                                   max_depth=6, # O resultado do GridSearch acaba tornando a árvore muito ilegível, então vamos manter 6 aqui\n",
    "                                   min_samples_leaf=best_min_leaf2, \n",
    "                                   min_samples_split=best_min_split2, \n",
    "                                   ccp_alpha=best_ccp_alpha2,\n",
    "                                   max_features=best_max_features2)\n",
    "\n",
    "clf_ccp2.fit(X_train_tree2, y_train_tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apesar do *best_max_depth2* ser 9, a visualização da árvore continua complicada. Por isso, vamos limitar *max_depth* em 6 para que a árvore seja mais legível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão Reestruturada - Treino\n",
    "tree_pred_ccp2T = clf_ccp2.predict(X_train_tree2)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Treino:\")\n",
    "print(classification_report(y_train_tree2, tree_pred_ccp2T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict da Árvore de Decisão Reestruturada - Teste\n",
    "tree_pred_ccp2 = clf_ccp2.predict(X_test_tree2)\n",
    "\n",
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Teste:\")\n",
    "print(classification_report(y_test_tree2, tree_pred_ccp2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com os parâmetros que colocamos na árvore, a acurácia permanece parecida com a da árvore anterior e ainda se mantém sem overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances_ccp2 = clf_ccp2.feature_importances_\n",
    "feature_importances_ccp2 = pd.DataFrame(\n",
    "    importances_ccp2, columns = ['Importance'], index=df2.drop('Situação', axis=1).columns).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances_ccp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assim como no modelo anterior, notamos que a *Bilirrubina* é a variável mais influente para a classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão Reestruturada\n",
    "fig_2 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf_ccp2,\n",
    "                      feature_names=df2.drop(columns=['Situação']).columns,\n",
    "                      class_names=clf_ccp2.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree2T = confusion_matrix(y_test_tree2, tree_pred2)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot2 = ConfusionMatrixDisplay(confusion_matrix=matrixTree2T, display_labels=clf_ccp2.classes_)\n",
    "matrixTreePlot2.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão Reestruturada - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Matriz de Confusão da Árvore Reestruturada permanece semelhante à matriz anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo de árvore de decisão para uso futuro\n",
    "\n",
    "print(\"O modelo de Árvore de Decisão Reestruturada foi salvo em:\")\n",
    "dump(clf_ccp2, 'models/modelos_morte/death_tree_fixed2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rede Neural**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nessa seção, vamos mudar o foco para utilizar um modelo de Rede Neural nas previsões. Como a rede neural exige que as classes sejam números e não strings, é necessário fazer um *label encoding* com a biblioteca do sklearn para converter a coluna **Situação** em números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2N = df2.copy()\n",
    "df2N['Situação'] = label_encoder.fit_transform(df2N['Situação'])\n",
    "\n",
    "X2N  = df2N.drop(columns=['Situação']).values\n",
    "y2N = df2N['Situação'].values\n",
    "\n",
    "X_train2N, X_test2N, y_train2N, y_test2N = train_test_split(X2N, y2N, test_size=0.2)\n",
    "X_train2N = scaler2.fit_transform(X_train2N)\n",
    "X_test2N = scaler2.transform(X_test2N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train2N.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aqui estamos inicializando uma rede neural com:\n",
    "\n",
    "    * camada de entrada com 32 neurônios e função de ativação *relu*;\n",
    "\n",
    "    * duas camadas com 64 neurônios;\n",
    "\n",
    "    * uma camada com 32 neurônios;\n",
    "\n",
    "    * camada de saída com 2 neurônios (para as duas classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A partir dessa célula, temos o treinamento do modelo de fato. Vamos rodar 200 épocas de 64 amostras cada, para conseguir fazer um treino relativamente rápido e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = neural2.fit(X_train2N, y_train2N, epochs=200, batch_size=64, validation_data=(X_test2N, y_test2N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy/loss\n",
    "train_acc2 = history2.history['accuracy']\n",
    "val_acc2 = history2.history['val_accuracy']\n",
    "train_loss2 = history2.history['loss']\n",
    "val_loss2 = history2.history['val_loss']\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_acc2, label='Training Accuracy')\n",
    "plt.plot(val_acc2, label='Validation Accuracy')\n",
    "plt.title('Accuracy Curves (Best Model)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com o gráfico anterior, podemos ver que a acurácia se estabiliza em torno de 85%, portanto, não é necessário continuar com mais épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss (error)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss2, label='Training Loss')\n",
    "plt.plot(val_loss2, label='Validation Loss')\n",
    "plt.title('Loss Curves (Best Model)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Report - Rede Neural - Treino:\")\n",
    "print(classification_report(y_train2N, np.argmax(neural2.predict(X_train2N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Report - Rede Neural - Teste:\")\n",
    "print(classification_report(y_test2N, np.argmax(neural2.predict(X_test2N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Após a análise das acurácias do treino e do teste, percebemos que o modelo também não está sofrendo de overfitting. Além disso, a acurácia do modelo aumentou consideravelmente, o que é um bom resultado, apesar de ainda haver possibilidade de melhora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de Rede Neural foi salvo em:\")\n",
    "dump(neural2, 'models/modelos_morte/death_neural2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Light Gradient Boosting Machine (LGBM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como uma análise final, vamos realizar a classificação utilizando o Light Gradient Boosting Machine (LGBM). Esse modelo, diferente dos outros, faz um processo de ensemble, que utiliza árvore de decisaã para tornar o modelo mais eficaz e prático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os datasets para LightGBM\n",
    "train_data2 = lgb.Dataset(X_train2N, label=y_train2N)\n",
    "valid_data2 = lgb.Dataset(X_test2N, label= y_test2N)\n",
    "\n",
    "# Define os parâmetros do modelo\n",
    "parameters2 = {\n",
    "    'objective': 'multiclass',  # Define o objetivo como classificação multiclasse\n",
    "    'boosting_type': 'gbdt',  # Usa Gradient Boosting Decision Tree\n",
    "    'metric': 'multi_logloss',  # Métrica de avaliação: log-loss para múltiplas classes\n",
    "    'num_class': len(np.unique(y2N)),  # Número de classes únicas em 'Situação'\n",
    "    'num_leaves': 16,  # Número máximo de folhas em cada árvore\n",
    "    'learning_rate': 0.05,  # Taxa de aprendizado do modelo\n",
    "    'feature_fraction': 0.9  # Fração de features usadas em cada iteração de construção da árvore\n",
    "}\n",
    "\n",
    "# Treina o modelo\n",
    "model_lgbm2 = lgb.train(parameters2, train_data2, valid_sets=[train_data2, valid_data2], num_boost_round=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsões\n",
    "y_train_pred_2 = model_lgbm2.predict(X_train2N)\n",
    "y_valid_pred_2 = model_lgbm2.predict(X_test2N)\n",
    "\n",
    "# Converte as previsões para rótulos de classe\n",
    "y_train_pred_2_labels = np.argmax(y_train_pred_2, axis=1)\n",
    "y_valid_pred_2_labels = np.argmax(y_valid_pred_2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia o modelo no conjunto de treino\n",
    "print(\"Report - LGBM - Treino:\")\n",
    "print(classification_report(y_train2N, y_train_pred_2_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia o modelo\n",
    "print(\"Report - LGBM - Teste:\")\n",
    "print(classification_report(y_test2N, y_valid_pred_2_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Algo interessante que acontece aqui é que o modelo conseguiu alcançar uma porcentagem de 100% de acurácia nos dados de treino! Isso normalmente poderia ser preocupante, mas perceba que a acurácia, a precisão e o recall nos dados se mantém na similares no treino e no teste, logo, não há overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixLGBM2T = confusion_matrix(y_test2N, y_valid_pred_2_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "matrixLGBMPlot2 = ConfusionMatrixDisplay(confusion_matrix=matrixLGBM2T, display_labels=np.unique(y2N))\n",
    "matrixLGBMPlot2.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('LightGBM - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por ser o modelo de previsão que possui a maior acurácia, a matriz de confusão do LGBM também é a que possui a maior quantidade de valores na diagonal principal, o que significa que a grande maioria das previsões está coerente com os dados reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de LightGBM foi salvo em:\")\n",
    "dump(model_lgbm2, 'models/modelos_morte/death_lightgbm2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparando Modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A seguir, vamos comparar os resultados dos modelos de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logistica\n",
    "print(\"Report - Regressão Logística - Teste:\")\n",
    "print(classification_report(y_test2, y_pred2, zero_division=0))\n",
    "\n",
    "# Árvore de Decisão\n",
    "print(\"\\nReport - Árvore de Decisão Reestruturada - Teste:\")\n",
    "print(classification_report(y_test_tree2, tree_pred_ccp2, zero_division=0))\n",
    "\n",
    "# Rede Neural\n",
    "print(\"\\nReport - Rede Neural - Teste:\")\n",
    "print(classification_report(y_test2N, np.argmax(neural2.predict(X_test2N), axis=1), zero_division=0))\n",
    "\n",
    "# LightGBM\n",
    "print(\"\\nReport - LGBM - Teste:\")\n",
    "print(classification_report(y_test2N, y_valid_pred_2_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verificando a importância das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística\n",
    "feature_names2 = df2.columns[1:]\n",
    "coefficients2 = logreg2.coef_\n",
    "coef_df2 = pd.DataFrame(coefficients2, columns=feature_names2)\n",
    "for i, class_name in enumerate(logreg2.classes_):\n",
    "    sorted_coef2 = coef_df2.iloc[i].sort_values(ascending=False)\n",
    "    print(f\"Importância das Features em relação a {class_name} na Regressão Logística:\\n\")\n",
    "    print(sorted_coef2)\n",
    "    break\n",
    "\n",
    "# Árvore de Decisão\n",
    "# Importância dos coeficientes\n",
    "importances2 = clf2.feature_importances_\n",
    "feature_importances2 = pd.DataFrame(\n",
    "    importances2,\n",
    "    columns = ['Importance'],\n",
    "    index=df2.drop('Situação', axis=1).columns\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features na Árvore de Decisão:\")\n",
    "print(feature_importances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Após a análise dos resultados, percebemos que o modelo de LightGBM e a de Rede Neural apresentam os melhores resultados. Porém, apesar da Rede Neural apresentar um resultado satisfatório, o modelo de LGBM apresenta a maior acurácia, precisão e recall. Dessa forma, o modelo LightGBM é o mais indicado para a classificação dos dados. Álem disso, ao analisar a importância das variáveis, percebemos que a Bilirrubina é a variável que provoca o maior impacto na classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Classificação 3: Ignorando Evento Transplante\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação e Ajuste dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ignora dados de *Transplante* e renomea a coluna para Morte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "\n",
    "# Retira as linhas que possuem a coluna 'Situação' com o valor 'Transplante'\n",
    "df3 = df3[df3['Situação'] != 'Transplante']\n",
    "\n",
    "# Renomeia a coluna 'Situação' para 'Morte'\n",
    "df3 = df3.rename(columns={'Situação': 'Morte'})\n",
    "\n",
    "# Mostra as primeiras e ultimas linhas do dataset\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Separação e Normalização de dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dividimos as colunas nas variáveis X3 e Y3, com Y3 posduindo os dados da coluna *Morte* e X3 as demais.\n",
    "    \n",
    "* Separamos os dados de ambas as variáveis em 80% para treino e 20% para teste.\n",
    "\n",
    "* Normalizamos os dados de X3 utilizando o *StandardScaler* e salvamos o scaler na pasta **scalers_morte** para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das variáveis independentes e dependentes\n",
    "X3 = np.array(df3.iloc[:, 1:].values)\n",
    "Y3 = np.array(df3.iloc[:, 0].values)\n",
    "\n",
    "# Divisão dos dados em treino e teste (80% treino e 20% teste)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3, Y3, test_size = 0.2)\n",
    "\n",
    "# Normalização dos Dados                                                              \n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(x_train3)\n",
    "x_test3 = scaler3.transform(x_test3)\n",
    "x_train3 = scaler3.transform(x_train3)\n",
    "\n",
    "# Mostra o tamanho dos dados de treino e teste\n",
    "print(\"Tamanho treinamento: \" + str(len(x_train3)))\n",
    "print(\"Tamanho teste: \" + str(len(x_test3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o scaler\n",
    "print(\"O modelo do scaler foi salvo em: \")\n",
    "dump(scaler3, 'scalers/scalers_morte/death_scaler3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regressão Logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nosso primeiro modelo de classificação será utilizando Regressão Logística. Vamos utilizar o objeto LogisticRegression e dar um fit() para treinar nosso modelo, e depois salvar a predição eu uma variável separada. Os resultados da regressão são exibidos através de uma tabela de resultados, com a precisão de cada classe, a acurácia geral e também uma matriz de confusão com as duas classes.\n",
    "\n",
    "* Por fim, o modelo de Regressão Logística é salvo na pasta *modelos_morte*, no arquivo nomeado *death_logreg3.joblib*, para que seja mais fácil de acessá-lo caso seja necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia Regressão Logistica\n",
    "logreg3 = LogisticRegression(max_iter=5000, n_jobs=-1)\n",
    "\n",
    "# Fit do Classificador\n",
    "logreg3.fit(x_train3, y_train3)\n",
    "\n",
    "# Predict do teste\n",
    "y_pred3 = logreg3.predict(x_test3)\n",
    "\n",
    "# Predict do treino\n",
    "y_pred3T = logreg3.predict(x_train3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados de Treino\n",
    "print(\"Report - Regressão Logística - Treino:\")\n",
    "print(classification_report(y_train3, y_pred3T, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados\n",
    "print(\"Report - Regressão Logística - Teste:\")\n",
    "print(classification_report(y_test3, y_pred3, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pelos resultados da acurácias do treino e do teste serem similiares, podemmos descartar o overfitting, porém vemos que o valor da acurácia do teste não é satisfatório por estar em torno de 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "feature_names3 = df3.columns[1:]\n",
    "coefficients3 = logreg3.coef_\n",
    "coef_df3 = pd.DataFrame(coefficients3, columns=feature_names3)\n",
    "for idx, class_name in enumerate(logreg3.classes_):\n",
    "    sorted_coef3 = coef_df3.iloc[idx].sort_values(ascending=False)\n",
    "    print(f\"Importância das Features em relação a {class_name}:\\n\")\n",
    "    print(sorted_coef3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No Resultado acima podemos verificar que o atributo com maior relação com a classe morte é a Bilirrubina, isso se deve ao fato deste atributo se relacionar com a falha da função hepática ou obstrução biliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo \n",
    "print(\"O modelo de Regressão Logística foi salvo em:\")\n",
    "dump(logreg3, 'models/modelos_morte/death_logreg3.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test3, y_pred3)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Morte', 'Sobreviveu'], yticklabels=['Morte', 'Sobreviveu'])\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Regressão Logística - Matriz de Confusão')\n",
    "\n",
    "# Mostra a matriz de confusão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando a matriz de confusão:\n",
    "\n",
    "    * É perceptível que obtivemo um melhor desempenho para a classe Sobreviveu, isto se deve ao fato de que a classe Sobreviveu possui mais exemplos do que a classe Morte.\n",
    "\n",
    "    * Temos quantidades próximas para a classificação correta de morte e classificação erronea de morte, isto se deve a baixa taxa de recall para a classe morte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tree3, X_test_tree3, y_train_tree3, y_test_tree3 = train_test_split(X3, Y3, test_size=0.2, random_state=0)\n",
    "# Instanciar a Árvore de Decisão\n",
    "clf3 = DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_leaf=5)\n",
    "\n",
    "clf3.fit(X_train_tree3, y_train_tree3)\n",
    "\n",
    "# Predict da Árvore de Decisão - Teste\n",
    "tree_pred3 = clf3.predict(X_test_tree3)\n",
    "\n",
    "# Predict da Árvore de Decisão - Treino\n",
    "tree_pred3T = clf3.predict(X_train_tree3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados - Treino\n",
    "print(\"Report - Árvore de Decisão - Treino:\")\n",
    "print(classification_report(y_train_tree3, tree_pred3T, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados - Teste\n",
    "print(\"Report - Árvore de Decisão - Teste:\")\n",
    "print(classification_report(y_test_tree3, tree_pred3, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neste modelo a acurácia está em torno de 89% indicando uma melhora em relação à Regressão Logística, além disso vemos que apesar dos dados continuarem desbalanceados, vemos que o recall das classes para o teste possui valores aproximados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances3 = clf3.feature_importances_\n",
    "feature_importances3 = pd.DataFrame(\n",
    "    importances3,\n",
    "    columns = ['Importance'],\n",
    "    index=df3.drop('Morte', axis=1).columns\n",
    ").sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ao verificar a importância das features podemos notar que novamente a Bilirrubina possui maior valor em relação as demais variaveis, portanto é mais utilizada para dividir os nós o que resulta na diminuição de impurezas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottar a Árvore de Decisão\n",
    "fig3 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf3,\n",
    "                      feature_names=df3.drop(columns=['Morte']).columns,\n",
    "                      class_names=clf3.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree3 = confusion_matrix(y_test_tree3, tree_pred3)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot3 = ConfusionMatrixDisplay(confusion_matrix=matrixTree3, display_labels=clf3.classes_)\n",
    "matrixTreePlot3.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando a matriz de confusão:\n",
    "    * O modelo ainda classifica alguns casos erroneamente, mas como o recall possui valores aproximados entre as classes, vemos que há um equilibrio para os casos classificados erroneamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando os resultados da Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test3[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rules(clf3, x_test3[55])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reestruturação da Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apesar da árvore de decisão entregar bons resultados, é possível melhorar o resultado através do GridSearchCV para encontrar os melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "path3 = clf3.cost_complexity_pruning_path(X_train_tree3, y_train_tree3)\n",
    "\n",
    "param_grid3 = {\n",
    "    'max_depth': range(2, 10),\n",
    "    'min_samples_split': range(2, 10),\n",
    "    'min_samples_leaf': range(1, 5),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': range(4, X3.shape[1] + 1),\n",
    "    'ccp_alpha': (0.0, 0.1, 0.5, 0.05, 0.005)\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=clf3, param_grid=param_grid3, cv = 7, verbose=2, n_jobs=-1)\n",
    "CV_clf.fit(X_train_tree3, y_train_tree3)\n",
    "\n",
    "best_max_depth3 = CV_clf.best_estimator_.max_depth\n",
    "best_min_split3 = CV_clf.best_estimator_.min_samples_split\n",
    "best_min_leaf3 = CV_clf.best_estimator_.min_samples_leaf\n",
    "best_criterion3 = CV_clf.best_estimator_.criterion\n",
    "best_max_features3 = CV_clf.best_estimator_.max_features\n",
    "best_ccp_alpha3 = CV_clf.best_estimator_.ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com os novos parâmentros, instanciamos uma nova árvore de decisão buscando melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar um novo objeto para a Árvore de Decisão Reestruturada\n",
    "clf_ccp3 = DecisionTreeClassifier(criterion=best_criterion3,\n",
    "                                   max_depth=6, # O resultado do GridSearch acaba tornando a árvore muito ilegível, então vamos manter 6 aqui\n",
    "                                   min_samples_leaf=best_min_leaf3, \n",
    "                                   min_samples_split=best_min_split3, \n",
    "                                   ccp_alpha=best_ccp_alpha3,\n",
    "                                   max_features=best_max_features3)\n",
    "\n",
    "clf_ccp3.fit(X_train_tree3, y_train_tree3)\n",
    "\n",
    "# Predict da Árvore de Decisão Reestruturada - Teste\n",
    "tree_pred_ccp3 = clf_ccp3.predict(X_test_tree3)\n",
    "\n",
    "# Predict da Árvore de Decisão Reestruturada - Treino\n",
    "tree_pred_ccp3T = clf_ccp3.predict(X_train_tree3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Treino:\")\n",
    "print(classification_report(y_train_tree3, tree_pred_ccp3T, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados\n",
    "print(\"Report - Árvore de Decisão Reestruturada - Teste:\")\n",
    "print(classification_report(y_test_tree3, tree_pred_ccp3, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A nova árvore atingiu cerca de 81% de acurácia, isto se deve principalmente por conta das limitações de niveis que foram impostas. Porém agora possuimos uma árvore com mais interpretabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes\n",
    "importances_ccp3 = clf_ccp3.feature_importances_\n",
    "feature_importances_ccp3 = pd.DataFrame(\n",
    "    importances_ccp3, columns = ['Importance'], index=df3.drop('Morte', axis=1).columns).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances_ccp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com base na análise da importância das features, a bilirrubina(mg/dl) é a feature mais importante na classificação, seguida pela albumina(gm/dl) e pela aspartato aminotransferase(U/L)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de Decisão Reestruturada\n",
    "fig_3 = plt.figure(figsize=(90,40))\n",
    "_ = tree.plot_tree(clf_ccp3,\n",
    "                      feature_names=df3.drop(columns=['Morte']).columns,\n",
    "                      class_names=clf_ccp3.classes_,\n",
    "                      filled=True,\n",
    "                      fontsize=10,\n",
    "                      )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixTree3T = confusion_matrix(y_test_tree3, tree_pred3)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "matrixTreePlot3 = ConfusionMatrixDisplay(confusion_matrix=matrixTree3T, display_labels=clf_ccp3.classes_)\n",
    "matrixTreePlot3.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Árvore de Decisão Reestruturada - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apesar da reestruturação da árvore de decisão. é possível notar que a taxa de recall continua bem próxima da árvore anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo de árvore de decisão para uso futuro\n",
    "print(\"\\nO modelo de Árvore de Decisão Corrigida foi salvo em:\")\n",
    "print(dump(clf_ccp3, 'models/modelos_morte/death_tree_fixed3.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rede Neural**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Buscando utilizar outro modelo para comparação, nesta seção utilizamos o modelo de Rede Neural. Este modelo necessita de que as classes não estejam em string, portanto é utilizado o *factorize* para transformar o valores string para binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3N = df.copy()\n",
    "\n",
    "# Retira as linhas que possuem a coluna 'Situação' com o valor 'Transplante'\n",
    "df3N = df3N[df3N['Situação'] != 'Transplante']\n",
    "\n",
    "df3N['Situação'] = pd.factorize(df3N['Situação'])[0]\n",
    "\n",
    "X3N  = df3N.drop(columns=['Situação']).values\n",
    "y3N = df3N['Situação'].values\n",
    "\n",
    "X_train3N, X_test3N, y_train3N, y_test3N = train_test_split(X3N, y3N, test_size=0.2)\n",
    "X_train3N = scaler3.fit_transform(X_train3N)\n",
    "X_test3N = scaler3.transform(X_test3N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(x_train3.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criação da rede neural 3:\n",
    "\n",
    "    * camada de entrada com 32 neurônios e função de ativação *relu*;\n",
    "\n",
    "    * duas camadas com 64 neurônios;\n",
    "\n",
    "    * uma camada com 32 neurônios;\n",
    "\n",
    "    * camada de saída com 2 neurônios (para as duas classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Abaixo teremos o treinamento da Rede Neural 3 com 200 épocas de 64 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = neural3.fit(X_train3N, y_train3N, epochs=200, batch_size=64, validation_data=(X_test3N, y_test3N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A acurácia começa a estabilizar entre 88%. Logo Abaixo temos os gráficos de acurácia e de perda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy/loss\n",
    "train_acc3 = history3.history['accuracy']\n",
    "val_acc3 = history3.history['val_accuracy']\n",
    "train_loss3 = history3.history['loss']\n",
    "val_loss3 = history3.history['val_loss']\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_acc3, label='Training Accuracy')\n",
    "plt.plot(val_acc3, label='Validation Accuracy')\n",
    "plt.title('Accuracy Curves (Best Model)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss (error)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss3, label='Training Loss')\n",
    "plt.plot(val_loss3, label='Validation Loss')\n",
    "plt.title('Loss Curves (Best Model)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de report de Treino\n",
    "print(\"Report - Dados de Treino:\")\n",
    "print(classification_report(y_train3N, np.argmax(neural3.predict(X_train3N), axis=1), zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de report de Teste\n",
    "print(\"Report - Dados de Teste:\")\n",
    "print(classification_report(y_test3N, np.argmax(neural3.predict(X_test3N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O modelo apresenta um recall razoavelmente bom apesar de um desbalanceamento para a classe de sobreviveu, com uma acurácia geral de 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de Rede Neural foi salvo em:\")\n",
    "dump(neural3, 'models/modelos_morte/death_neural3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Light Gradient Boosting Machine (LGBM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nesta seção utilizaremos o **Light Gradient Boosting Machine** (ou LGBM). O qual faz um processo de ensemble de tipo boosting, que vai combinar vários modelos do mesmo algoritmo de forma sequencial. Assim como a Rede Neural, utiliza os dados em binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os datasets para LightGBM\n",
    "train_data3 = lgb.Dataset(X_train3N, label=y_train3N)\n",
    "valid_data3 = lgb.Dataset(X_test3N, label= y_test3N)\n",
    "\n",
    "# Define os parâmetros do modelo\n",
    "parameters3 = {\n",
    "    'objective': 'multiclass',  # Define o objetivo como classificação multiclasse\n",
    "    'boosting_type': 'gbdt',  # Usa Gradient Boosting Decision Tree\n",
    "    'metric': 'multi_logloss',  # Métrica de avaliação: log-loss para múltiplas classes\n",
    "    'num_class': len(np.unique(y3N)),  # Número de classes únicas em 'Situação'\n",
    "    'num_leaves': 31,  # Número máximo de folhas em cada árvore\n",
    "    'learning_rate': 0.05,  # Taxa de aprendizado do modelo\n",
    "    'feature_fraction': 0.9  # Fração de features usadas em cada iteração de construção da árvore\n",
    "}\n",
    "\n",
    "# Treina o modelo\n",
    "model_lgbm3 = lgb.train(parameters3, train_data3, valid_sets=[train_data3, valid_data3], num_boost_round=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsões\n",
    "y_train_pred_3 = model_lgbm3.predict(X_train3N)\n",
    "y_valid_pred_3 = model_lgbm3.predict(X_test3N)\n",
    "\n",
    "# Converte as previsões para rótulos de classe\n",
    "y_train_pred_3_labels = np.argmax(y_train_pred_3, axis=1)\n",
    "y_valid_pred_3_labels = np.argmax(y_valid_pred_3, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia o modelo no conjunto de treino\n",
    "print(\"Report - LGBM - Treino:\")\n",
    "print(classification_report(y_train3N, y_train_pred_3_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avalia o modelo\n",
    "print(\"Report - LGBM - Teste:\")\n",
    "print(classification_report(y_test3N, y_valid_pred_3_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A acurácia geral do modelo no conjunto de treino é de 100%, mas apesar disso, na tabela de teste vemos que o modelo possui uma acurácia de 98% isso siginifica que o modelo se adaptou bem ao conjunto de treino,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "matrixLGBM3T = confusion_matrix(y_test3N, y_valid_pred_3_labels)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "matrixLGBMPlot3 = ConfusionMatrixDisplay(confusion_matrix=matrixLGBM3T, display_labels=np.unique(y3N))\n",
    "matrixLGBMPlot3.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('LightGBM - Matriz de Confusão')\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analisando a matriz de confusão vemos que em relação aos modelos anteriores o LGMB é o que consegue classificar melhor, apesar de um leve desbalanceamento entre as classes que não altera a eficácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O modelo de LightGBM foi salvo em:\")\n",
    "dump(model_lgbm3, 'models/modelos_morte/death_lightgbm3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparando os Modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Abaixo teremos os reports dos testes de cada modelo utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados - Teste - Regressão Logística\n",
    "print(\"Report - Regressão Logistica:\")\n",
    "print(classification_report(y_test3, y_pred3, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de Resultados - Teste - Árvore de Decisão\n",
    "print(\"Report - Árvore de Decisão Reestruturada:\")\n",
    "print(classification_report(y_test_tree3, tree_pred_ccp3, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de report de Teste - Rede Neural\n",
    "print(\"Report - Rede Neural:\")\n",
    "print(classification_report(y_test3N, np.argmax(neural3.predict(X_test3N), axis=1), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tabela de report de Teste - LGBM\n",
    "print(\"Report - LGBM:\")\n",
    "print(classification_report(y_test3N, y_valid_pred_3_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A seguir as features de Rede Neural e da Ávore de Decisão Reestruturada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes - Regressão Logística\n",
    "feature_names3 = df3.columns[1:]\n",
    "coefficients3 = logreg3.coef_\n",
    "coef_df3 = pd.DataFrame(coefficients3, columns=feature_names3)\n",
    "for idx, class_name in enumerate(logreg3.classes_):\n",
    "    sorted_coef3 = coef_df3.iloc[idx].sort_values(ascending=False)\n",
    "    print(f\"Importância das Features em relação a {class_name} na Regressão Logistica:\\n\")\n",
    "    print(sorted_coef3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância dos coeficientes - Árvore de Decisão\n",
    "importances_ccp3 = clf_ccp3.feature_importances_\n",
    "feature_importances_ccp3 = pd.DataFrame(\n",
    "    importances_ccp3, columns = ['Importance'], index=df3.drop('Morte', axis=1).columns).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das Features:\")\n",
    "print(feature_importances_ccp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliação dos Modelos\n",
    "\n",
    "    Desempenho dos Modelos\n",
    "    Ao comparar os resultados dos modelos utilizados, os dois modelos com maior desempenho são o LGBM e a Rede Neural, nesta ordem. Isso se deve a dois fatores principais:\n",
    "\n",
    "    * Rede Neural: Proporcionou um balanceamento do recall entre as classes \"Sobreviveu\" e \"Morte\", mesmo com a diferença de volume de dados entre elas.\n",
    "    \n",
    "    * LGBM: Apresentou uma alta acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importância das Variáveis\n",
    "\n",
    "    Entre as variáveis utilizadas para construir as classificações, nos modelos de Regressão Logística e Árvore de Decisão, a Bilirrubina se destaca como o atributo mais importante:\n",
    "\n",
    "    * Regressão Logística:\n",
    "        A Bilirrubina possui uma correlação forte e inversa com a variável \"Morte\". Isso significa que níveis mais altos de bilirrubina estão associados a um maior risco de morte.\n",
    "        \n",
    "    * Árvore de Decisão:\n",
    "        A Bilirrubina é responsável por pelo menos 50% da redução de impurezas na árvore de decisão. Isso indica que essa variável é frequentemente usada para dividir os nós e melhorar a pureza da árvore.\n",
    "        A importância da Bilirrubina se deve ao fato de este atributo estar relacionado com a perda da função hepática, o que está associado a um maior risco de morte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusão\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
